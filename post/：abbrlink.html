<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Hexo</title><meta name="author" content="ğŸ˜Š"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.2.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Hexo</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/#Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/"> About</a></li><li class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://phower.me"> Blog</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>ğŸ˜Š</h3><p class="author-bio">â•°(*Â°â–½Â°*)â•¯</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weibo" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weixin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-qq" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fas fa-rss" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="/" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="/" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div><a class="cv-links" href="/attaches/CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>My Detail CV.</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">ã€ŠSpark HA & Yarné…ç½®ã€‹</h2><article><h1 id="ã€ŠSpark-HA-amp-Yarné…ç½®ã€‹"><a href="#ã€ŠSpark-HA-amp-Yarné…ç½®ã€‹" class="headerlink" title="ã€ŠSpark HA &amp; Yarné…ç½®ã€‹"></a>ã€ŠSpark HA &amp; Yarné…ç½®ã€‹</h1><p>Spark-Standalone-HAæ¨¡å¼<br>Spark Standaloneé›†ç¾¤æ˜¯Master-Slavesæ¶æ„çš„é›†ç¾¤æ¨¡å¼,å’Œå¤§éƒ¨åˆ†çš„Master-Slavesç»“æ„é›†ç¾¤ä¸€æ ·,å­˜åœ¨<br>ç€Master å•ç‚¹æ•…éšœ(SPOF)çš„é—®é¢˜ã€‚ç®€å•ç†è§£ä¸ºï¼Œspark-Standalone æ¨¡å¼ä¸‹ä¸º master èŠ‚ç‚¹æ§åˆ¶å…¶ä»–èŠ‚<br>ç‚¹ï¼Œå½“ master èŠ‚ç‚¹å‡ºç°æ•…éšœæ—¶ï¼Œé›†ç¾¤å°±ä¸å¯ç”¨äº†ã€‚ spark-Standalone-HA æ¨¡å¼ä¸‹<br>master èŠ‚ç‚¹ä¸å›ºå®šï¼Œå½“ä¸€ä¸ªå®•æœºæ—¶ï¼Œç«‹å³æ¢å¦ä¸€å°ä¸º master ä¿éšœä¸å‡ºç°æ•…éšœã€‚<br>æ­¤å¤„å› ä¸ºå…ˆå‰é…ç½®æ—¶çš„ zookeeper ç‰ˆæœ¬å’Œ spark ç‰ˆæœ¬ä¸å¤ªå…¼å®¹ï¼Œå¯¼è‡´æ­¤æ¨¡å¼æœ‰æ•…éšœï¼Œéœ€è¦é‡æ–°ä¸‹<br>è½½é…ç½®æ–°çš„ç‰ˆæœ¬çš„ zookeeper<br>é…ç½®ä¹‹å‰éœ€è¦åˆ é™¤ä¸‰å°ä¸»æœºçš„ æ—§ç‰ˆ zookeeper ä»¥åŠ å¯¹åº”çš„è½¯è¿æ¥<br>åœ¨ master èŠ‚ç‚¹ä¸Šé‡æ–°è¿›è¡Œå‰é¢é…ç½®çš„ zookeeper æ“ä½œ</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   1.ä¸Šä¼ apache-zookeeper-3.7.0-bin.tar.gz åˆ°&#x2F;export&#x2F;server&#x2F;ç›®å½•ä¸‹ å¹¶è§£å‹æ–‡ä»¶ 2.åœ¨ &#x2F;export&#x2F;server ç›®å½•ä¸‹åˆ›å»ºè½¯è¿æ¥ 3.è¿›å…¥ &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F; å°† zoo_sample.cfg æ–‡ä»¶å¤åˆ¶ä¸ºæ–°æ–‡ä»¶ zoo.cfg 4.æ¥ä¸Šæ­¥ç»™ zoo.cfg æ·»åŠ å†…å®¹ 5.è¿›å…¥ &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas ç›®å½•åœ¨æ­¤ç›®å½•ä¸‹åˆ›å»º myid æ–‡ä»¶ï¼Œå°† 1 å†™å…¥è¿› å»6.å°† master èŠ‚ç‚¹ä¸­ &#x2F;export&#x2F;server&#x2F;zookeeper-3.7.0 è·¯å¾„ä¸‹å†…å®¹æ¨é€ç»™slave1 å’Œ slave2 7.æ¨é€æˆåŠŸåï¼Œåˆ†åˆ«åœ¨ slave1 å’Œ slave2 ä¸Šåˆ›å»ºè½¯è¿æ¥ 8.æ¥ä¸Šæ­¥æ¨é€å®Œæˆåå°† slave1 å’Œ slave2 çš„ &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;æ–‡ä»¶å¤¹ ä¸‹çš„ myid ä¸­çš„å†…å®¹åˆ†åˆ«æ”¹ä¸º 2 å’Œ 3 é…ç½®ç¯å¢ƒå˜é‡ï¼š å› å…ˆå‰é…ç½® zookeeper æ—¶å€™åˆ›å»ºè¿‡è½¯è¿æ¥ä¸”ä»¥ â€™zookeeperâ€˜ ä¸ºè·¯å¾„ï¼Œæ‰€ä»¥ä¸ç”¨é…ç½®ç¯å¢ƒå˜é‡ï¼Œæ­¤ å¤„ä¹Ÿæ˜¯åˆ›å»ºè½¯è¿æ¥çš„æ–¹ä¾¿ä¹‹å¤„</p>
</blockquote>
</blockquote>
<p>è¿›å…¥ &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf æ–‡ä»¶å¤¹ ä¿®æ”¹ spark-env.sh æ–‡ä»¶å†…å®¹</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf<br>    vim spark-env.sh</p>
</blockquote>
</blockquote>
<p>ä¸º 83 è¡Œå†…å®¹åŠ ä¸Šæ³¨é‡Šï¼Œæ­¤éƒ¨åˆ†åŸä¸ºæŒ‡å®š æŸå°ä¸»æœº åš master ï¼ŒåŠ ä¸Šæ³¨é‡Šåå³ä¸º ä»»ä½•ä¸»æœºéƒ½<br>å¯ä»¥åš master</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   ç»“æœæ˜¾ç¤ºï¼š<br>     â€¦â€¦<br>      82 # å‘ŠçŸ¥Sparkçš„masterè¿è¡Œåœ¨å“ªä¸ªæœºå™¨ä¸Š 83 # export SPARK_MASTER_HOST&#x3D;master<br>     â€¦â€¦â€¦</p>
</blockquote>
</blockquote>
<p>æ–‡æœ«æ·»åŠ å†…å®¹</p>
<blockquote>
<blockquote>
<blockquote>
<p>SPARK_DAEMON_JAVA_OPTS&#x3D;â€-Dspark.deploy.recoveryMode&#x3D;ZOOKEEPER -<br>       Dspark.deploy.zookeeper.url&#x3D;master:2181,slave1:2181,slave2:2181 - Dspark.deploy.zookeeper.dir&#x3D;&#x2F;spark-haâ€<br>        #spark.deploy.recoveryMode<br>        æŒ‡å®šHAæ¨¡å¼ åŸºäºZookeeperå®ç°<br>        #æŒ‡å®šZookeeperçš„è¿æ¥åœ°å€<br>        #æŒ‡å®šåœ¨Zookeeperä¸­æ³¨å†Œä¸´æ—¶èŠ‚ç‚¹çš„è·¯å¾„</p>
</blockquote>
</blockquote>
</blockquote>
<p>åˆ†å‘ spark-env.sh åˆ° salve1 å’Œ slave2 ä¸Š</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>scp spark-env.sh slave1:/export/server/spark/conf/ 
scp spark-env.sh slave2:/export/server/spark/conf/
</code></pre>
</blockquote>
</blockquote>
<p>å¯åŠ¨ä¹‹å‰ç¡®ä¿ Zookeeper å’Œ HDFS å‡å·²ç»å¯åŠ¨<br>å¯åŠ¨é›†ç¾¤:</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   #åœ¨ master ä¸Š å¯åŠ¨ä¸€ä¸ªmaster å’Œå…¨éƒ¨worker &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-all.sh # æ³¨æ„, ä¸‹é¢å‘½ä»¤åœ¨ slave1 ä¸Šæ‰§è¡Œ å¯åŠ¨ slave1 ä¸Šçš„ master åšå¤‡ç”¨ master &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin&#x2F;start-master.sh<br>    ç»“æœæ˜¾ç¤ºï¼š<br>    (base) [root@master ~]# jps<br>    37328 DataNode<br>    41589 Master<br>    35798 QuorumPeerMain<br>    38521 ResourceManager<br>    46281 Jps<br>    38907 NodeManager<br>    41821 Worker<br>    36958 NameNode (base)<br>    [root@slave1 sbin]# jps<br>    36631 DataNode<br>    48135 Master<br>    35385 QuorumPeerMain<br>    37961 NodeManager<br>    40970 Worker<br>    48282 Jps<br>    37276 SecondaryNameNode</p>
</blockquote>
</blockquote>
<p>è®¿é—® WebUI ç•Œé¢</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>http://master:8081/
</code></pre>
<p>   <a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
<p>æ­¤æ—¶ kill æ‰ master ä¸Šçš„ master å‡è®¾ master ä¸»æœºå®•æœºæ‰</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   #masterä¸»æœº master çš„è¿›ç¨‹å· kill -9 41589 ç»“æœæ˜¾ç¤ºï¼š (base) [root@master ~]# jps 37328 DataNode 90336 Jps 35798 QuorumPeerMain 38521 ResourceManager 38907 NodeManager 41821 Worker 36958 NameNode</p>
</blockquote>
</blockquote>
<p>è®¿é—® slave1 çš„ WebUI</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
</blockquote>
<p>è¿›è¡Œä¸»å¤‡åˆ‡æ¢çš„æµ‹è¯•<br>æäº¤ä¸€ä¸ª spark ä»»åŠ¡åˆ°å½“å‰ æ´»è·ƒçš„ masterä¸Š :</p>
<blockquote>
<blockquote>
<blockquote>
<p>&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit â€“master spark:&#x2F;&#x2F;master:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 1000</p>
</blockquote>
</blockquote>
</blockquote>
<p>å¤åˆ¶æ ‡ç­¾ kill æ‰ master çš„ è¿›ç¨‹å·<br>å†æ¬¡è®¿é—® master çš„ WebUI</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://master:8081/">http://master:8081/</a><br>      ç½‘é¡µè®¿é—®ä¸äº†ï¼</p>
</blockquote>
</blockquote>
</blockquote>
<p>å†æ¬¡è®¿é—® slave1 çš„ WebUI</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
</blockquote>
<p>å¯ä»¥çœ‹åˆ°å½“å‰æ´»è·ƒçš„ master æç¤ºä¿¡æ¯</p>
<blockquote>
<blockquote>
<blockquote>
<p>(base) [root@master ~]# &#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit â€“master spark:&#x2F;&#x2F;master:7077 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 1000 22&#x2F;03&#x2F;29 16:11:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platformâ€¦ using builtin-java classes where applicable 22&#x2F;03&#x2F;29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnectâ€¦ 22&#x2F;03&#x2F;29 16:12:16 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnectionâ€¦ 22&#x2F;03&#x2F;29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnectâ€¦ Pi is roughly 3.140960 (base) [root@master ~]#</p>
</blockquote>
</blockquote>
</blockquote>
<p>Spark On YARNæ¨¡å¼</p>
<blockquote>
<blockquote>
<blockquote>
<p>åœ¨å·²æœ‰YARNé›†ç¾¤çš„å‰æä¸‹åœ¨å•ç‹¬å‡†å¤‡Spark StandAloneé›†ç¾¤,å¯¹èµ„æºçš„åˆ©ç”¨å°±ä¸é«˜.Spark On YARN, æ— </p>
</blockquote>
</blockquote>
</blockquote>
<p>éœ€éƒ¨ç½²Sparké›†ç¾¤, åªè¦æ‰¾ä¸€å°æœåŠ¡å™¨, å……å½“Sparkçš„å®¢æˆ·ç«¯<br>ä¿è¯ HADOOP_CONF_å’Œ DIR_YARN_CONF_DIR å·²ç»é…ç½®åœ¨ spark-env.sh å’Œç¯å¢ƒå˜é‡ä¸­ ï¼ˆæ³¨: å‰é¢é…ç½®spark-Standlone æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰</p>
<blockquote>
<blockquote>
<blockquote>
<p>spark-env.sh æ–‡ä»¶éƒ¨åˆ†æ˜¾ç¤ºï¼š â€¦. 77 ## HADOOPè½¯ä»¶é…ç½®æ–‡ä»¶ç›®å½•ï¼Œè¯»å–HDFSä¸Šæ–‡ä»¶å’Œè¿è¡ŒYARNé›†ç¾¤ 78 HADOOP_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop 79 YARN_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop â€¦.</p>
</blockquote>
</blockquote>
</blockquote>
<p>é“¾æ¥åˆ° YARN ä¸­ï¼ˆæ³¨: äº¤äº’å¼ç¯å¢ƒ pyspark å’Œ spark-shell æ— æ³•è¿è¡Œ clusteræ¨¡å¼ï¼‰<br>bin&#x2F;pyspark â€“master yarn â€“deploy-mode client|cluster # â€“deploy-mode é€‰é¡¹æ˜¯æŒ‡å®šéƒ¨ç½²æ¨¡å¼, é»˜è®¤æ˜¯ å®¢æˆ·ç«¯æ¨¡å¼ # clientå°±æ˜¯å®¢æˆ·ç«¯æ¨¡å¼ # clusterå°±æ˜¯é›†ç¾¤æ¨¡å¼ # â€“deploy-mode ä»…å¯ä»¥ç”¨åœ¨YARNæ¨¡å¼ä¸‹<br> bin&#x2F;spark-shell â€“master yarn â€“deploy-mode client|cluster<br>bin&#x2F;spark-submit â€“master yarn â€“deploy-mode client|cluster &#x2F;xxx&#x2F;xxx&#x2F;xxx.py å‚æ•°</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>  spark-submit å’Œ spark-shell å’Œ pysparkçš„ç›¸å…³å‚æ•°</p>
</blockquote>
</blockquote>
<ul>
<li>bin&#x2F;pyspark: pysparkè§£é‡Šå™¨sparkç¯å¢ƒ - bin&#x2F;spark-shell: scalaè§£é‡Šå™¨sparkç¯å¢ƒ - bin&#x2F;spark-submit: æäº¤jaråŒ…æˆ–Pythonæ–‡ä»¶æ‰§è¡Œçš„å·¥å…· - bin&#x2F;spark-sql: sparksqlå®¢æˆ·ç«¯å·¥å…·<br>  è¿™4ä¸ªå®¢æˆ·ç«¯å·¥å…·çš„å‚æ•°åŸºæœ¬é€šç”¨.ä»¥spark-submit ä¸ºä¾‹: bin&#x2F;spark-submit â€“master spark:&#x2F;&#x2F;master:7077 xxx.py&#96;<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>  Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]<br>   Usage: spark-submit â€“kill [submission ID] â€“master [spark:&#x2F;&#x2F;â€¦]<br>   Usage: spark-submit â€“status [submission ID] â€“master [spark:&#x2F;&#x2F;â€¦]<br>   Usage: spark-submit run-example [options] example-class [example args] </p>
<blockquote>
</blockquote>
<p>   Options: â€“master MASTER_URL spark:&#x2F;&#x2F;host:port, mesos:&#x2F;&#x2F;host:port, yarn, k8s:&#x2F;&#x2F;<a href="https://host:port">https://host:port</a>, or </p>
<blockquote>
</blockquote>
<p>   local (Default: local[*]). â€“deploy-mode DEPLOY_MODE éƒ¨ç½²æ¨¡å¼ client æˆ–è€… cluster é»˜è®¤æ˜¯client â€“class CLASS_NAME è¿è¡Œjavaæˆ–è€…scala class(for Java &#x2F; Scala apps). â€“name NAME ç¨‹åºçš„åå­— â€“jars JARS Comma-separated list of jars to include on the </p>
<blockquote>
</blockquote>
<p>   driver and executor classpaths. â€“packages Comma-separated list of maven coordinates of </p>
<blockquote>
</blockquote>
<p>   jars to include on the driver and executor classpaths. Will </p>
<blockquote>
</blockquote>
<p>   search the local maven repo, then maven central and any </p>
<blockquote>
</blockquote>
<p>   additional remote repositories given by â€“repositories. The </p>
<blockquote>
</blockquote>
<p>   format for the coordinates should be </p>
<blockquote>
</blockquote>
<p>   groupId:artifactId:version.<br>   â€“exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided in<br>â€“ packages to avoid dependency conflicts. â€“repositories Comma-separated list of additional remote repositories to search for the maven coordinates given with<br> â€“ packages.<br> â€“py-files PY_FILES æŒ‡å®šPythonç¨‹åºä¾èµ–çš„å…¶å®ƒpythonæ–‡ä»¶<br> â€“files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName).<br>  â€“archives ARCHIVES Comma-separated list of archives to be extracted into the working directory of each executor.<br> â€“conf,<br> -c PROP&#x3D;VALUE æ‰‹åŠ¨æŒ‡å®šé…ç½®<br> â€“properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf&#x2F;spark- defaults.conf. â€“driver-memory MEM Driverçš„å¯ç”¨å†…å­˜(Default: 1024M). â€“driver-java-options Driverçš„ä¸€äº›Javaé€‰é¡¹ â€“driver-library-path Extra library path entries to pass to the driver. â€“driver-class-path Extra class path entries to pass to the driver. Note that jars added with â€“jars are automatically included in the classpath.<br> â€“executor-memory MEM Executorçš„å†…å­˜ (Default: 1G).<br> â€“proxy-user NAME User to impersonate when submitting the application. This argument does not work with<br> â€“principal &#x2F;<br> â€“keytab.<br> â€“help,<br> -h æ˜¾ç¤ºå¸®åŠ©æ–‡ä»¶<br>  â€“verbose,<br>  -v Print additional debug output. â€“version, æ‰“å°ç‰ˆæœ¬ Cluster deploy mode only(é›†ç¾¤æ¨¡å¼ä¸“å±):<br>   â€“driver-cores NUM Driverå¯ç”¨çš„çš„CPUæ ¸æ•°(Default: 1). Spark standalone or Mesos with cluster deploy mode only:<br>   â€“supervise å¦‚æœç»™å®š, å¯ä»¥å°è¯•é‡å¯Driver Spark standalone, Mesos or K8s with cluster deploy mode only:<br>   â€“kill SUBMISSION_ID æŒ‡å®šç¨‹åºID kill â€“status SUBMISSION_ID æŒ‡å®šç¨‹åºID æŸ¥çœ‹è¿è¡ŒçŠ¶æ€ Spark standalone, Mesos and Kubernetes only:<br>   â€“total-executor-cores NUM æ•´ä¸ªä»»åŠ¡å¯ä»¥ç»™Executorå¤šå°‘ä¸ªCPUæ ¸å¿ƒç”¨ Spark standalone, YARN and Kubernetes only:<br>    â€“executor-cores NUM å•ä¸ªExecutorèƒ½ä½¿ç”¨å¤šå°‘CPUæ ¸å¿ƒ Spark on YARN and Kubernetes only(YARNæ¨¡å¼ä¸‹):<br>    â€“num-executors NUM Executoråº”è¯¥å¼€å¯å‡ ä¸ª<br>    â€“principal PRINCIPAL Principal to be used to login to KDC.<br>    â€“keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. Spark on YARN only:<br>    â€“queue QUEUE_NAME æŒ‡å®šè¿è¡Œçš„YARNé˜Ÿåˆ—(Default: â€œdefaultâ€)</p>
</blockquote>
</blockquote>
</li>
</ul>
<p>å¯åŠ¨ YARN çš„å†å²æœåŠ¡å™¨</p>
<blockquote>
<blockquote>
<blockquote>
<p>cd &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;sbin .&#x2F;mr-jobhistory-daemon.sh start historyserver</p>
</blockquote>
</blockquote>
</blockquote>
<p>è®¿é—®WebUIç•Œé¢</p>
<blockquote>
<blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://master:19888/">http://master:19888/</a></p>
</blockquote>
</blockquote>
</blockquote>
<p>client æ¨¡å¼æµ‹è¯•</p>
<blockquote>
<blockquote>
<blockquote>
<p>SPARK_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;spark ${SPARK_HOME}&#x2F;bin&#x2F;spark-submit â€“master yarn â€“deploy-mode client â€“ driver-memory 512m â€“executor-memory 512m â€“num-executors 1 â€“total- executor-cores 2 ${SPARK_HOME}&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py</p>
</blockquote>
</blockquote>
</blockquote>
<p>cluster æ¨¡å¼æµ‹è¯•</p>
<blockquote>
<blockquote>
<blockquote>
<p>SPARK_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;spark ${SPARK_HOME}&#x2F;bin&#x2F;spark-submit â€“master yarn â€“deploy-mode cluster â€“driver- memory 512m â€“executor-memory 512m â€“num-executors 1 â€“total-executor-cores 2 â€“conf â€œspark.pyspark.driver.python&#x3D;&#x2F;root&#x2F;anaconda3&#x2F;bin&#x2F;python3â€ â€“conf â€œspark.pyspark.python&#x3D;&#x2F;root&#x2F;anaconda3&#x2F;bin&#x2F;python3â€ ${SPARK_HOME}&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3**</p>
</blockquote>
</blockquote>
</blockquote>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/#Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/"> About</a></li><li class="nav_item"><a class="nav-page" target="_blank" rel="noopener" href="https://phower.me"> Blog</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2022 by ğŸ˜Š</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>